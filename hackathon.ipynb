{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c39d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m north_indian_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuisines\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNorth Indian\u001b[39m\u001b[38;5;124m'\u001b[39m, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 5: Count unique restaurant names\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m count \u001b[38;5;241m=\u001b[39m north_indian_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 6: Display the result\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of restaurants serving North Indian cuisine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Convert Google Drive share link to downloadable link\n",
    "file_id = '1IfdLKZJR_ETJUa3BQYM11j0GSEVt6YcT'\n",
    "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "df = pd.read_csv(download_url)\n",
    "\n",
    "# Step 3: Clean the 'cuisines' column\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['cuisines'], inplace=True)\n",
    "df['cuisines'] = df['cuisines'].astype(str)\n",
    "\n",
    "# Step 4: Find restaurants that serve 'North Indian' cuisine\n",
    "north_indian_df = df[df['cuisines'].str.contains('North Indian', case=False, na=False)]\n",
    "\n",
    "# Step 5: Count unique restaurant names\n",
    "count = north_indian_df['name'].nunique()\n",
    "\n",
    "# Step 6: Display the result\n",
    "print(f\"Number of restaurants serving North Indian cuisine: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c26c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Columns in the dataset:\n",
      "['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n",
      "\n",
      "üçõ Number of restaurants serving North Indian cuisine: 20767\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Import Libraries\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Step 1: Load local CSV file\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"  # Use raw string to avoid path errors\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ‚úÖ Step 2: Show available columns\n",
    "print(\"üìã Columns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ‚úÖ Step 3: Data cleaning\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['cuisines'], inplace=True)\n",
    "df['cuisines'] = df['cuisines'].astype(str)\n",
    "\n",
    "# ‚úÖ Step 4: Filter for 'North Indian' cuisine\n",
    "north_indian_df = df[df['cuisines'].str.contains('North Indian', case=False, na=False)]\n",
    "\n",
    "# ‚úÖ Step 5: Count number of restaurants offering North Indian cuisine\n",
    "restaurant_count = len(north_indian_df)\n",
    "\n",
    "# üñ®Ô∏è Final Output\n",
    "print(f\"\\nüçõ Number of restaurants serving North Indian cuisine: {restaurant_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85c2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçΩÔ∏è Most commonly offered cuisine in Bangalore is: North Indian (20767 restaurants)\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Load the dataset from local path\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# üßπ Clean the data\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['cuisines'], inplace=True)\n",
    "df['cuisines'] = df['cuisines'].astype(str)\n",
    "\n",
    "# üçΩÔ∏è Extract most commonly offered cuisine\n",
    "# Some rows contain multiple cuisines like \"North Indian, Chinese\", so we split them\n",
    "cuisine_series = df['cuisines'].str.split(',').explode().str.strip()\n",
    "\n",
    "# Count frequency of each cuisine\n",
    "most_common_cuisine = cuisine_series.value_counts().idxmax()\n",
    "count = cuisine_series.value_counts().max()\n",
    "\n",
    "# üñ®Ô∏è Output the result\n",
    "print(f\"üçΩÔ∏è Most commonly offered cuisine in Bangalore is: {most_common_cuisine} ({count} restaurants)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a8f727",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['location', 'approx_cost(for two people)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14016\\814515952.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Clean data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'location'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'approx_cost(for two people)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m df['approx_cost(for two people)'] = (\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'approx_cost(for two people)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['location', 'approx_cost(for two people)']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean data\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=['location', 'approx_cost(for two people)'], inplace=True)\n",
    "df['approx_cost(for two people)'] = (\n",
    "    df['approx_cost(for two people)']\n",
    "    .astype(str)\n",
    "    .str.replace(',', '')\n",
    "    .str.replace('nan', '')\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Filter for the given localities\n",
    "localities = ['Banashankari', 'Church Street', 'Indiranagar', 'Whitefield']\n",
    "filtered_df = df[df['location'].isin(localities)]\n",
    "\n",
    "# Calculate average cost for each\n",
    "avg_cost = filtered_df.groupby('location')['approx_cost(for two people)'].mean()\n",
    "\n",
    "# Find the locality with the highest cost\n",
    "highest_locality = avg_cost.idxmax()\n",
    "highest_value = avg_cost.max()\n",
    "\n",
    "# Print the result\n",
    "print(f\"üìç Locality with the highest average dining cost: {highest_locality}\")\n",
    "print(f\"üí∞ Average cost for two: ‚Çπ{highest_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a03a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Column names in the dataset:\n",
      "['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"üìã Column names in the dataset:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d49025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Columns in dataset:\n",
      "['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['location', 'approx_cost(for two people)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14016\\4140086469.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcost_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'approx_cost(for two people)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlocation_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'location'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# ‚úÖ Step 4: Drop missing values in the required columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlocation_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# ‚úÖ Step 5: Clean the cost column (remove commas, extract numbers, convert to float)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m df[cost_col] = (\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['location', 'approx_cost(for two people)']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Step 1: Load your local CSV file\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ‚úÖ Step 2: Show all column names to confirm structure\n",
    "print(\"üìã Columns in dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ‚úÖ Step 3: Rename columns if needed (match with your actual columns)\n",
    "# Adjust these if your dataset uses slightly different names\n",
    "cost_col = 'approx_cost(for two people)'\n",
    "location_col = 'location'\n",
    "\n",
    "# ‚úÖ Step 4: Drop missing values in the required columns\n",
    "df.dropna(subset=[location_col, cost_col], inplace=True)\n",
    "\n",
    "# ‚úÖ Step 5: Clean the cost column (remove commas, extract numbers, convert to float)\n",
    "df[cost_col] = (\n",
    "    df[cost_col]\n",
    "    .astype(str)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .str.extract(r'(\\d+\\.?\\d*)')[0]  # Extract numeric part\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 6: Compare only the 4 localities from the question\n",
    "localities = ['Banashankari', 'Church Street', 'Indiranagar', 'Whitefield']\n",
    "filtered_df = df[df[location_col].isin(localities)]\n",
    "\n",
    "# ‚úÖ Step 7: Calculate average cost and find the highest one\n",
    "avg_cost = filtered_df.groupby(location_col)[cost_col].mean()\n",
    "highest_locality = avg_cost.idxmax()\n",
    "highest_value = avg_cost.max()\n",
    "\n",
    "# ‚úÖ Step 8: Print the result\n",
    "print(\"\\nüìä Average Cost for Two by Locality:\")\n",
    "print(avg_cost)\n",
    "\n",
    "print(f\"\\n‚úÖ Locality with the highest average dining cost: **{highest_locality}**\")\n",
    "print(f\"üí∞ Average cost for two: ‚Çπ{highest_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7b9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Average Cost for Two People by Locality:\n",
      "listed_incity\n",
      "Church Street    771.990104\n",
      "Indiranagar      654.753655\n",
      "Whitefield       579.159925\n",
      "Banashankari     401.551564\n",
      "Name: approx_costfor_two_people, dtype: float64\n",
      "\n",
      "‚úÖ Correct answer: Church Street\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fix column names based on your data\n",
    "cost_col = 'approx_costfor_two_people'\n",
    "location_col = 'listed_incity'\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(subset=[location_col, cost_col], inplace=True)\n",
    "\n",
    "# Clean the cost column\n",
    "df[cost_col] = (\n",
    "    df[cost_col]\n",
    "    .astype(str)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .str.extract(r'(\\d+\\.?\\d*)')[0]\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Filter for the 4 specific localities\n",
    "localities = ['Banashankari', 'Church Street', 'Indiranagar', 'Whitefield']\n",
    "filtered_df = df[df[location_col].isin(localities)]\n",
    "\n",
    "# Calculate average cost by locality\n",
    "avg_cost = filtered_df.groupby(location_col)[cost_col].mean().sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"üìä Average Cost for Two People by Locality:\")\n",
    "print(avg_cost)\n",
    "\n",
    "# Show the locality with the highest average cost\n",
    "highest_locality = avg_cost.idxmax()\n",
    "print(f\"\\n‚úÖ Correct answer: {highest_locality}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e97ade",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[rate_col, vote_col, rest_type_col], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Clean and convert the 'rate' column\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df[rate_col] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     17\u001b[0m     df[rate_col]\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m.\u001b[39mreplace([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m], pd\u001b[38;5;241m.\u001b[39mNA)\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m df[rate_col]\u001b[38;5;241m.\u001b[39mfillna(df[rate_col]\u001b[38;5;241m.\u001b[39mmean(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Filter for restaurants with more than 1000 votes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fix column names based on your dataset\n",
    "vote_col = 'votes'\n",
    "rate_col = 'rate'\n",
    "rest_type_col = 'rest_type'\n",
    "\n",
    "# Drop missing or invalid ratings\n",
    "df.dropna(subset=[rate_col, vote_col, rest_type_col], inplace=True)\n",
    "\n",
    "# Clean and convert the 'rate' column\n",
    "df[rate_col] = (\n",
    "    df[rate_col]\n",
    "    .astype(str)\n",
    "    .str.replace('/5', '', regex=False)\n",
    "    .replace(['NEW', '-', 'nan'], pd.NA)\n",
    "    .astype(float)\n",
    ")\n",
    "df[rate_col].fillna(df[rate_col].mean(), inplace=True)\n",
    "\n",
    "# Filter for restaurants with more than 1000 votes\n",
    "filtered_df = df[df[vote_col] > 1000]\n",
    "\n",
    "# Group by restaurant type and calculate average rating\n",
    "top_types = (\n",
    "    filtered_df.groupby(rest_type_col)[rate_col]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Display top result\n",
    "print(\"üìä Average Rating by Restaurant Type (votes > 1000):\")\n",
    "print(top_types.head())\n",
    "\n",
    "# Show the top-rated one\n",
    "top_rest_type = top_types.idxmax()\n",
    "top_rating = top_types.max()\n",
    "print(f\"\\n‚úÖ Correct answer: {top_rest_type} (Avg Rating: {top_rating:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3e6128",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Clean 'rate' column\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      9\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mreplace([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m], pd\u001b[38;5;241m.\u001b[39mNA)\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Filter for restaurants with more than 1000 votes and non-null rest_type\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean 'rate' column\n",
    "df['rate'] = (\n",
    "    df['rate']\n",
    "    .astype(str)\n",
    "    .str.replace('/5', '', regex=False)\n",
    "    .replace(['NEW', '-', 'nan'], pd.NA)\n",
    "    .astype(float)\n",
    ")\n",
    "df['rate'].fillna(df['rate'].mean(), inplace=True)\n",
    "\n",
    "# Filter for restaurants with more than 1000 votes and non-null rest_type\n",
    "df_filtered = df[(df['votes'] > 1000) & (df['rest_type'].notna())]\n",
    "\n",
    "# Group by restaurant type and calculate average rating\n",
    "top_rated_type = (\n",
    "    df_filtered.groupby('rest_type')['rate']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Display the top one\n",
    "top_rest_type = top_rated_type.idxmax()\n",
    "top_rating = top_rated_type.max()\n",
    "\n",
    "print(\"‚úÖ Restaurant type with top rating and over 1000 votes:\")\n",
    "print(f\"{top_rest_type} (Average Rating: {top_rating:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea8e621",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'approx_cost(for two people)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'approx_cost(for two people)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Clean the cost column\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cost_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapprox_cost(for two people)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m df[cost_col] \u001b[38;5;241m=\u001b[39m df[cost_col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m     11\u001b[0m df[cost_col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[cost_col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get minimum cost\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'approx_cost(for two people)'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the cost column\n",
    "cost_col = 'approx_cost(for two people)'\n",
    "df[cost_col] = df[cost_col].astype(str).str.replace(',', '').replace('nan', np.nan)\n",
    "df[cost_col] = pd.to_numeric(df[cost_col], errors='coerce')\n",
    "\n",
    "# Get minimum cost\n",
    "min_cost = df[cost_col].min()\n",
    "print(f\"Minimum cost to eat out in Bangalore: ‚Çπ{int(min_cost)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921dd6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n",
      "‚úÖ Minimum cost to eat out in Bangalore: ‚Çπ40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Show all columns (optional - helpful for debugging)\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n",
    "# Step 3: Use the correct column name\n",
    "cost_col = 'approx_costfor_two_people'\n",
    "\n",
    "# Step 4: Clean the cost column\n",
    "df[cost_col] = df[cost_col].astype(str).str.replace(',', '').replace('nan', np.nan)\n",
    "df[cost_col] = pd.to_numeric(df[cost_col], errors='coerce')\n",
    "\n",
    "# Step 5: Drop missing cost values\n",
    "df.dropna(subset=[cost_col], inplace=True)\n",
    "\n",
    "# Step 6: Get the minimum cost\n",
    "min_cost = df[cost_col].min()\n",
    "print(f\"‚úÖ Minimum cost to eat out in Bangalore: ‚Çπ{int(min_cost)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22ac4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n",
      "‚úÖ Minimum cost to eat out in Bangalore is: ‚Çπ40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Fix column name (check exact name if needed)\n",
    "# Expected: 'approx_costfor_two_people'\n",
    "print(\"Available columns:\", df.columns.tolist())  # Debug if needed\n",
    "\n",
    "# Step 3: Clean 'approx_costfor_two_people' column\n",
    "cost_col = 'approx_costfor_two_people'\n",
    "df[cost_col] = (\n",
    "    df[cost_col]\n",
    "    .astype(str)\n",
    "    .str.replace(',', '', regex=False)   # Remove commas like 1,000 ‚Üí 1000\n",
    "    .replace(['nan', '-', 'None'], np.nan)\n",
    ")\n",
    "\n",
    "df[cost_col] = pd.to_numeric(df[cost_col], errors='coerce')\n",
    "\n",
    "# Step 4: Drop rows with NaN in cost\n",
    "df.dropna(subset=[cost_col], inplace=True)\n",
    "\n",
    "# Step 5: Find minimum cost\n",
    "min_cost = int(df[cost_col].min())\n",
    "\n",
    "print(f\"‚úÖ Minimum cost to eat out in Bangalore is: ‚Çπ{min_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562a36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of votes received by any restaurant with online ordering: 16832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweet\\AppData\\Local\\Temp\\ipykernel_14016\\488806044.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  online_df['votes'] = pd.to_numeric(online_df['votes'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for correct column name for online order\n",
    "if 'online_order' not in df.columns or 'votes' not in df.columns:\n",
    "    print(\"Required columns are missing.\")\n",
    "else:\n",
    "    # Filter only restaurants with online ordering enabled\n",
    "    online_df = df[df['online_order'].astype(str).str.lower() == 'yes']\n",
    "\n",
    "    # Convert votes column to numeric (in case of any issues)\n",
    "    online_df['votes'] = pd.to_numeric(online_df['votes'], errors='coerce')\n",
    "\n",
    "    # Get the maximum number of votes\n",
    "    max_votes = online_df['votes'].max()\n",
    "\n",
    "    print(f\"Maximum number of votes received by any restaurant with online ordering: {max_votes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c07001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating of restaurants that serve both North Indian and Chinese cuisines: 3.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the 'rate' column\n",
    "df['rate'] = df['rate'].astype(str).str.replace('/5', '', regex=False).replace(['NEW', '-', 'nan'], pd.NA)\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Filter restaurants that serve both North Indian and Chinese cuisines\n",
    "df['cuisines'] = df['cuisines'].astype(str)\n",
    "filtered_df = df[df['cuisines'].str.contains('North Indian', case=False, na=False) &\n",
    "                 df['cuisines'].str.contains('Chinese', case=False, na=False)]\n",
    "\n",
    "# Calculate the average rating\n",
    "average_rating = filtered_df['rate'].mean()\n",
    "\n",
    "print(f\"Average rating of restaurants that serve both North Indian and Chinese cuisines: {round(average_rating, 1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "489ab4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most profitable area based on estimated potential revenue:\n",
      "listed_incity\n",
      "Koramangala 7th Block    1.001584e+09\n",
      "Name: potential_revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "# Fix cost column\n",
    "df['approx_costfor_two_people'] = df['approx_costfor_two_people'].astype(str).str.replace(',', '').replace('nan', np.nan)\n",
    "df['approx_costfor_two_people'] = pd.to_numeric(df['approx_costfor_two_people'], errors='coerce')\n",
    "\n",
    "# Clean 'votes' column\n",
    "df['votes'] = pd.to_numeric(df['votes'], errors='coerce')\n",
    "\n",
    "# Drop missing data\n",
    "df.dropna(subset=['listed_incity', 'approx_costfor_two_people', 'votes'], inplace=True)\n",
    "\n",
    "# Estimate potential revenue = cost * votes\n",
    "df['potential_revenue'] = df['approx_costfor_two_people'] * df['votes']\n",
    "\n",
    "# Group by area/locality\n",
    "revenue_by_area = df.groupby('listed_incity')['potential_revenue'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Show top area\n",
    "print(\"Most profitable area based on estimated potential revenue:\")\n",
    "print(revenue_by_area.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2fd51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant types with lowest ratings and high vote counts:\n",
      "                     avg_rating  total_votes  count\n",
      "rest_type                                          \n",
      "Bakery, Quick Bites    3.397807        11970    228\n",
      "Food Court             3.472946        35688    499\n",
      "Takeaway, Delivery     3.513622        90276   1292\n",
      "Quick Bites            3.546113      1476809  13944\n",
      "Delivery               3.569286       223766   1680\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "# Clean and convert rate column\n",
    "df['rate'] = (\n",
    "    df['rate']\n",
    "    .astype(str)\n",
    "    .str.replace('/5', '', regex=False)\n",
    "    .replace(['NEW', '-', 'nan'], np.nan)\n",
    ")\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Clean votes\n",
    "df['votes'] = pd.to_numeric(df['votes'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values in important columns\n",
    "df.dropna(subset=['rest_type', 'rate', 'votes'], inplace=True)\n",
    "\n",
    "# Group by restaurant type: get average rating and total votes\n",
    "rest_group = df.groupby('rest_type').agg(\n",
    "    avg_rating=('rate', 'mean'),\n",
    "    total_votes=('votes', 'sum'),\n",
    "    count=('rest_type', 'count')\n",
    ").sort_values(by='avg_rating')\n",
    "\n",
    "# Filter for types with high vote counts (indicating popularity)\n",
    "complaint_candidates = rest_group[rest_group['total_votes'] > 10000]\n",
    "\n",
    "print(\"Restaurant types with lowest ratings and high vote counts:\")\n",
    "print(complaint_candidates.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39dfc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'location' not found in dataset. Please verify column names.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "# Clean rate column\n",
    "df['rate'] = (\n",
    "    df['rate']\n",
    "    .astype(str)\n",
    "    .str.replace('/5', '', regex=False)\n",
    "    .replace(['NEW', '-', 'nan'], pd.NA)\n",
    ")\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Clean votes column\n",
    "df['votes'] = pd.to_numeric(df['votes'], errors='coerce')\n",
    "\n",
    "# Clean online_order column (just in case)\n",
    "df['online_order'] = df['online_order'].astype(str).str.lower()\n",
    "\n",
    "# Filter conditions\n",
    "filtered_df = df[\n",
    "    (df['rate'] > 4.2) &\n",
    "    (df['votes'] > 500) &\n",
    "    (df['online_order'] == 'yes')\n",
    "]\n",
    "\n",
    "# Group by area/locality\n",
    "if 'location' in filtered_df.columns:\n",
    "    top_areas = filtered_df['location'].value_counts()\n",
    "    print(\"Top areas with high-rated, highly voted, online-ordering restaurants:\")\n",
    "    print(top_areas.head(5))\n",
    "else:\n",
    "    print(\"Column 'location' not found in dataset. Please verify column names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a98cce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå 'location' column not found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "# Clean 'rate' column\n",
    "df['rate'] = (\n",
    "    df['rate']\n",
    "    .astype(str)\n",
    "    .str.replace('/5', '', regex=False)\n",
    "    .replace(['NEW', '-', 'nan'], pd.NA)\n",
    ")\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Clean 'votes' column\n",
    "df['votes'] = pd.to_numeric(df['votes'], errors='coerce')\n",
    "\n",
    "# Clean 'online_order' column\n",
    "df['online_order'] = df['online_order'].astype(str).str.lower()\n",
    "\n",
    "# Filter based on conditions\n",
    "filtered_df = df[\n",
    "    (df['rate'] > 4.2) &\n",
    "    (df['votes'] > 500) &\n",
    "    (df['online_order'] == 'yes')\n",
    "]\n",
    "\n",
    "# Check if 'location' column exists and get top location\n",
    "if 'location' in filtered_df.columns:\n",
    "    top_location = filtered_df['location'].value_counts().idxmax()\n",
    "    print(f\"‚úÖ Zomato should invest in: {top_location}\")\n",
    "else:\n",
    "    print(\"‚ùå 'location' column not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2fd6f9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'location'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     16\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[\n\u001b[0;32m     17\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4.2\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m     18\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvotes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m     19\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline_order\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m ]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Group by location and count\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m top_area \u001b[38;5;241m=\u001b[39m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZomato should invest in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_area\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'location'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the rate column\n",
    "df['rate'] = df['rate'].astype(str).str.replace('/5', '', regex=False)\n",
    "df['rate'] = df['rate'].replace(['NEW', '-', 'nan'], pd.NA)\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Apply the filter: high rating, high votes, and online order = Yes\n",
    "filtered_df = df[\n",
    "    (df['rate'] > 4.2) &\n",
    "    (df['votes'] > 500) &\n",
    "    (df['online_order'].str.lower() == 'yes')\n",
    "]\n",
    "\n",
    "# Group by location and count\n",
    "top_area = filtered_df['location'].value_counts().idxmax()\n",
    "\n",
    "print(f\"Zomato should invest in: {top_area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83d27d01",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'listed_in(city)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'listed_in(city)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 26\u001b[0m\n\u001b[0;32m     19\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[\n\u001b[0;32m     20\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4.2\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m     21\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvotes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m     22\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline_order\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m ]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Group by location and count\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m top_area \u001b[38;5;241m=\u001b[39m filtered_df[location_col]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZomato should invest in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_area\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'listed_in(city)'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the rate column\n",
    "df['rate'] = df['rate'].astype(str).str.replace('/5', '', regex=False)\n",
    "df['rate'] = df['rate'].replace(['NEW', '-', 'nan'], pd.NA)\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Now the location is likely in this column\n",
    "location_col = 'listed_in(city)'\n",
    "\n",
    "# Apply the filter: high rating, high votes, and online order = Yes\n",
    "filtered_df = df[\n",
    "    (df['rate'] > 4.2) &\n",
    "    (df['votes'] > 500) &\n",
    "    (df['online_order'].str.lower() == 'yes')\n",
    "]\n",
    "\n",
    "# Group by location and count\n",
    "top_area = filtered_df[location_col].value_counts().idxmax()\n",
    "\n",
    "print(f\"Zomato should invest in: {top_area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ed74de6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'listed_in(city)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'listed_in(city)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m total_online \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(online_df)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Online order restaurants in Banashankari\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m banashankari_online \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(online_df[online_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlisted_in(city)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbanashankari\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate percentage\u001b[39;00m\n\u001b[0;32m     20\u001b[0m percentage \u001b[38;5;241m=\u001b[39m (banashankari_online \u001b[38;5;241m/\u001b[39m total_online) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'listed_in(city)'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Filter only restaurants that offer online ordering\n",
    "online_df = df[df['online_order'].str.lower() == 'yes']\n",
    "\n",
    "# Total number of online order restaurants\n",
    "total_online = len(online_df)\n",
    "\n",
    "# Online order restaurants in Banashankari\n",
    "banashankari_online = len(online_df[online_df['listed_in(city)'].str.lower() == 'banashankari'])\n",
    "\n",
    "# Calculate percentage\n",
    "percentage = (banashankari_online / total_online) * 100\n",
    "print(f\"Percentage of online orders in Banashankari: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b2051bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show all column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0984ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"One or more required columns are missing: ['online_order', 'listed_in_city']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m required_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline_order\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlisted_in_city\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_cols):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more required columns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# ‚úÖ Step 5: Filter rows with online ordering\u001b[39;00m\n\u001b[0;32m     19\u001b[0m online_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monline_order\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: \"One or more required columns are missing: ['online_order', 'listed_in_city']\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Step 1: Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ‚úÖ Step 2: Clean column names for easier access\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "# ‚úÖ Step 3: Check actual column names (Optional - you can uncomment to see)\n",
    "# print(df.columns.tolist())\n",
    "\n",
    "# ‚úÖ Step 4: Ensure required columns exist\n",
    "required_cols = ['online_order', 'listed_in_city']\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise KeyError(f\"One or more required columns are missing: {required_cols}\")\n",
    "\n",
    "# ‚úÖ Step 5: Filter rows with online ordering\n",
    "online_df = df[df['online_order'].str.lower() == 'yes']\n",
    "\n",
    "# ‚úÖ Step 6: Total online order restaurants\n",
    "total_online = len(online_df)\n",
    "\n",
    "# ‚úÖ Step 7: Online order restaurants in Banashankari\n",
    "banashankari_online = len(online_df[online_df['listed_in_city'].str.lower() == 'banashankari'])\n",
    "\n",
    "# ‚úÖ Step 8: Calculate percentage\n",
    "percentage = (banashankari_online / total_online) * 100\n",
    "print(f\"Percentage of online orders in Banashankari: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55a630ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'listed_in_city'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'listed_in_city'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvotes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3.0\u001b[39m)]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Get locality with max such restaurants\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m most_common_locality \u001b[38;5;241m=\u001b[39m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlisted_in_city\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe locality with the most restaurants with >500 votes and rating < 3.0 is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_common_locality\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'listed_in_city'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "# Clean 'rate' column\n",
    "df['rate'] = df['rate'].astype(str).str.replace('/5', '').replace(['NEW', '-', 'nan'], pd.NA)\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Filter for restaurants with votes > 500 and rating < 3.0\n",
    "filtered_df = df[(df['votes'] > 500) & (df['rate'] < 3.0)]\n",
    "\n",
    "# Get locality with max such restaurants\n",
    "most_common_locality = filtered_df['listed_in_city'].value_counts().idxmax()\n",
    "\n",
    "print(f\"The locality with the most restaurants with >500 votes and rating < 3.0 is: {most_common_locality}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c3d34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset:\n",
      "['online_order', 'book_table', 'rate', 'votes', 'rest_type', 'dish_liked', 'cuisines', 'approx_costfor_two_people', 'listed_intype', 'listed_incity']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'location'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvotes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3.0\u001b[39m)]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Use appropriate location column (adjust if needed after print)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Usually it's 'location', but check output of df.columns\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m most_common_locality \u001b[38;5;241m=\u001b[39m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe locality with the most restaurants with >500 votes and rating < 3.0 is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_common_locality\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'location'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print all column names\n",
    "print(\"Columns in dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Clean and convert rate column\n",
    "df['rate'] = df['rate'].astype(str).str.replace('/5', '').replace(['NEW', '-', 'nan'], pd.NA)\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Filter restaurants with more than 500 votes and rating less than 3.0\n",
    "filtered_df = df[(df['votes'] > 500) & (df['rate'] < 3.0)]\n",
    "\n",
    "# Use appropriate location column (adjust if needed after print)\n",
    "# Usually it's 'location', but check output of df.columns\n",
    "most_common_locality = filtered_df['location'].value_counts().idxmax()\n",
    "\n",
    "print(f\"The locality with the most restaurants with >500 votes and rating < 3.0 is: {most_common_locality}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eab55b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The locality with the most restaurants with >500 votes and rating < 3.0 is: Brookefield\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print all column names (optional, for debugging)\n",
    "# print(\"Columns in dataset:\")\n",
    "# print(df.columns.tolist())\n",
    "\n",
    "# Clean and convert 'rate' column\n",
    "df['rate'] = df['rate'].astype(str).str.replace('/5', '').replace(['NEW', '-', 'nan'], pd.NA)\n",
    "df['rate'] = pd.to_numeric(df['rate'], errors='coerce')\n",
    "\n",
    "# Filter restaurants with >500 votes and rating < 3.0\n",
    "filtered_df = df[(df['votes'] > 500) & (df['rate'] < 3.0)]\n",
    "\n",
    "# Use 'listed_incity' as the locality column\n",
    "most_common_locality = filtered_df['listed_incity'].value_counts().idxmax()\n",
    "\n",
    "print(f\"The locality with the most restaurants with >500 votes and rating < 3.0 is: {most_common_locality}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "859302ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locality with the highest restaurant type diversity: BTM (61 unique types)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop missing rest_type or listed_incity\n",
    "df = df.dropna(subset=['rest_type', 'listed_incity'])\n",
    "\n",
    "# Count unique rest types per locality\n",
    "diversity = df.groupby('listed_incity')['rest_type'].nunique()\n",
    "\n",
    "# Get the locality with the highest diversity\n",
    "top_diversity_locality = diversity.idxmax()\n",
    "top_diversity_count = diversity.max()\n",
    "\n",
    "print(f\"Locality with the highest restaurant type diversity: {top_diversity_locality} ({top_diversity_count} unique types)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9c01cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Buffet Cost: ‚Çπnan\n",
      "Average Delivery Cost: ‚Çπ415.05\n",
      "Average Cost Difference: ‚Çπnan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\sweet\\Downloads\\zomato_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean cost column\n",
    "df['approx_costfor_two_people'] = df['approx_costfor_two_people'].astype(str).str.replace(',', '').replace('nan', pd.NA)\n",
    "df['approx_costfor_two_people'] = pd.to_numeric(df['approx_costfor_two_people'], errors='coerce')\n",
    "\n",
    "# Drop NaNs\n",
    "df = df.dropna(subset=['rest_type', 'approx_costfor_two_people'])\n",
    "\n",
    "# Filter buffet and delivery restaurants\n",
    "buffet_df = df[df['rest_type'].str.lower().str.contains('buffet', na=False)]\n",
    "delivery_df = df[df['rest_type'].str.lower().str.contains('delivery', na=False)]\n",
    "\n",
    "# Calculate average costs\n",
    "buffet_avg = buffet_df['approx_costfor_two_people'].mean()\n",
    "delivery_avg = delivery_df['approx_costfor_two_people'].mean()\n",
    "\n",
    "# Cost difference\n",
    "diff = buffet_avg - delivery_avg\n",
    "\n",
    "print(f\"Average Buffet Cost: ‚Çπ{buffet_avg:.2f}\")\n",
    "print(f\"Average Delivery Cost: ‚Çπ{delivery_avg:.2f}\")\n",
    "print(f\"Average Cost Difference: ‚Çπ{diff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40fd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
